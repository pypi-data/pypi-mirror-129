
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Bag of Words &#8212; Orange3 Text Mining  documentation</title>
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="bag-of-words">
<h1>Bag of Words<a class="headerlink" href="#bag-of-words" title="Permalink to this headline">¶</a></h1>
<p>Generates a bag of words from the input corpus.</p>
<p><strong>Inputs</strong></p>
<ul class="simple">
<li><p>Corpus: A collection of documents.</p></li>
</ul>
<p><strong>Outputs</strong></p>
<ul class="simple">
<li><p>Corpus: Corpus with bag of words features appended.</p></li>
</ul>
<p><strong>Bag of Words</strong> model creates a corpus with word counts for each data instance (document). The count can be either absolute, binary (contains or does not contain) or sublinear (logarithm of the term frequency). Bag of words model is required in combination with <a class="reference internal" href="wordenrichment.html"><span class="doc">Word Enrichment</span></a> and could be used for predictive modelling.</p>
<p><img alt="../_images/Bag-of-Words-stamped.png" src="../_images/Bag-of-Words-stamped.png" /></p>
<ol class="simple">
<li><p>Parameters for <a class="reference external" href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf">bag of words</a> model:</p>
<ul class="simple">
<li><p>Term Frequency:</p>
<ul>
<li><p>Count: number of occurrences of a word in a document</p></li>
<li><p>Binary: word appears or does not appear in the document</p></li>
<li><p>Sublinear: logarithm of term frequency (count)</p></li>
</ul>
</li>
<li><p>Document Frequency:</p>
<ul>
<li><p>(None)</p></li>
<li><p>IDF: <a class="reference external" href="http://nlp.stanford.edu/IR-book/html/htmledition/inverse-document-frequency-1.html">inverse document frequency</a></p></li>
<li><p><a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html">Smooth IDF</a>: adds one to document frequencies to prevent zero division.</p></li>
</ul>
</li>
<li><p>Regulariation:</p>
<ul>
<li><p>(None)</p></li>
<li><p>L1 (Sum of elements): normalizes vector length to sum of elements</p></li>
<li><p>L2 (Euclidean): normalizes vector length to sum of squares</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Produce a report.</p></li>
<li><p>If <em>Commit Automatically</em> is on, changes are communicated automatically. Alternatively press <em>Commit</em>.</p></li>
</ol>
<div class="section" id="example">
<h2>Example<a class="headerlink" href="#example" title="Permalink to this headline">¶</a></h2>
<p>In the first example we will simply check how the bag of words model looks like. Load <em>book-excerpts.tab</em> with <a class="reference internal" href="corpus-widget.html"><span class="doc">Corpus</span></a> widget and connect it to <strong>Bag of Words</strong>. Here we kept the defaults - a simple count of term frequencies. Check what the <strong>Bag of Words</strong> outputs with <strong>Data Table</strong>. The final column in white represents term frequencies for each document.</p>
<p><img alt="../_images/Bag-of-Words-Example1.png" src="../_images/Bag-of-Words-Example1.png" /></p>
<p>In the second example we will try to predict document category. We are still using the <em>book-excerpts.tab</em> data set, which we sent through <a class="reference internal" href="preprocesstext.html"><span class="doc">Preprocess Text</span></a> with default parameters. Then we connected <strong>Preprocess Text</strong> to <strong>Bag of Words</strong> to obtain term frequencies by which we will compute the model.</p>
<p><img alt="../_images/Bag-of-Words-Example2.png" src="../_images/Bag-of-Words-Example2.png" /></p>
<p>Connect <strong>Bag of Words</strong> to <strong>Test &amp; Score</strong> for predictive modelling. Connect <strong>SVM</strong> or any other classifier to <strong>Test &amp; Score</strong> as well (both on the left side). <strong>Test &amp; Score</strong> will now compute performance scores for each learner on the input. Here we got quite impressive results with SVM. Now we can check, where the model made a mistake.</p>
<p>Add <strong>Confusion Matrix</strong> to <strong>Test &amp; Score</strong>. Confusion matrix displays correctly and incorrectly classified documents. <em>Select Misclassified</em> will output misclassified documents, which we can further inspect with <a class="reference internal" href="corpusviewer.html"><span class="doc">Corpus Viewer</span></a>.</p>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">Orange3 Text Mining</a></h1>








<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="corpus-widget.html">Corpus</a></li>
<li class="toctree-l1"><a class="reference internal" href="importdocuments.html">Import Documents</a></li>
<li class="toctree-l1"><a class="reference internal" href="guardian-widget.html">The Guardian</a></li>
<li class="toctree-l1"><a class="reference internal" href="nytimes.html">NY Times</a></li>
<li class="toctree-l1"><a class="reference internal" href="pubmed.html">Pubmed</a></li>
<li class="toctree-l1"><a class="reference internal" href="twitter-widget.html">Twitter</a></li>
<li class="toctree-l1"><a class="reference internal" href="wikipedia-widget.html">Wikipedia</a></li>
<li class="toctree-l1"><a class="reference internal" href="preprocesstext.html">Preprocess Text</a></li>
<li class="toctree-l1"><a class="reference internal" href="similarityhashing.html">Similarity Hashing</a></li>
<li class="toctree-l1"><a class="reference internal" href="sentimentanalysis.html">Sentiment Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="tweetprofiler.html">Tweet Profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="corpusviewer.html">Corpus Viewer</a></li>
<li class="toctree-l1"><a class="reference internal" href="wordcloud.html">Word Cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="concordance.html">Concordance</a></li>
<li class="toctree-l1"><a class="reference internal" href="geomap.html">GeoMap</a></li>
<li class="toctree-l1"><a class="reference internal" href="wordenrichment.html">Word Enrichment</a></li>
<li class="toctree-l1"><a class="reference internal" href="duplicatedetection.html">Duplicate Detection</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../scripting/corpus.html">Corpus</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scripting/preprocess.html">Preprocessor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scripting/twitter.html">Twitter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scripting/nyt.html">New York Times</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scripting/guardian.html">The Guardian</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scripting/wikipedia.html">Wikipedia</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scripting/bagofwords.html">Bag of Words</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scripting/topicmodeling.html">Topic Modeling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scripting/tag.html">Tag</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scripting/async.html">Async Module</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2018, Laboratory of Bioinformatics, Faculty of Computer Science, University of Ljubljana.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 2.0.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/widgets/bagofwords.md.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>