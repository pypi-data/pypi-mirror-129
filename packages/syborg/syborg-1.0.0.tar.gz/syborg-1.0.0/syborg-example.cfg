# This is an example syborg configuration file, showing how I use it in my own
# personal backups. It is composed of three types of sections: backups, archives
# and repositories.

# Backup sections are named "backup.[name]" and define backup jobs that can be
# executed with "syborg backup [name]". Running this command will add one or
# more archives to one or more borg repositories. Archives names here correspond
# to archive.[name] sections below
[backup.main]
# home/sysconf correspond to some files in home directory plus system
# configuration.
archives = home,sysconf
# home/sysconf archives will be small because they contain mostly text files and
# git repositories, so it is very cheap to send them to multiple locations.
# Every time we run this backup job we will send the archives to a local
# repository, to a cloud-mirrored repository and to rsync.net via ssh
repositories = local,cloud,rsyncnet
# These are the most important files I have, so I enhance the default retention
# policy which is --keep-last=2 (see the default config values at the beginning
# of syborg.py)
borg.prune.keep-hourly = 24
borg.prune.keep-daily = 7
borg.prune.keep-weekly = 4
borg.prune.keep-monthly = 6
borg.prune.keep-yearly = 1

[backup.blobs]
# The "blobs" archive contains some big files, such as cd/dvd images and some
# virtual machine images. this backup job will send the archive to both to
# our local repository and to rsync.net (which I have the 100gb borg plan), but
# not to cloud provides since I don't have much space there.
archives = blobs
repositories = local,rsyncnet

[backup.all-local]
# This job sends all my archives to the local repository. fsroot is the root
# directory of my debian installation.
archives = home,sysconf,blobs,fsroot
repositories = local

[backup.all-sg4tb]
# This job is a copy of the above, but it sends the archive to my seagate 4tb
# external drive. I have it defined separately because this job only runs when I
# plug my hd (I have a udev rule that mounts it at the correct location and runs
# the job automatically)
archives = home,sysconf,fsroot,blobs
repositories = sg4tb

# By keeping archives as separate definitions, it becomes easy to backup the
# same sets of files to multiple repositories and at different schedules.
[archive.home]
# This will backup some important data in my home directory. "basedir" is the
# directory borg will be executed from, so all files included in the archive
# will be relative to that directory. Note that since this is intended to be run
# as the root user, we have to specify the full path to the basedir. If syborg
# is run as a normal user, it should be fine to use "~" to specify the home
# directory.
basedir = /home/tarruda
include =
 Documents
 Pictures
 git
 .local/share/applications
 .ssh
 .gnupg

[archive.sysconf]
# This includes system configuration, including syborg config files which are
# stored in the root user directory. Note that this is also included by the
# "fsroot" archive, but only one copy is stored due to borg's deduplication
# feature.
basedir = /
include =
 etc
 root/.config
 root/.ssh

[archive.blobs]
# Big files such as cd images and VM images. Unlike "sysconf", this archive is
# stored in a separate filesystem mounted at /blobs, so it is not included by
# the "fsroot" archive (by default, we pass --one-file-system to borg)
basedir = /blobs
include =
 virtual-machines
 iso-images

[archive.fsroot]
# This archive includes everything in the root directory
basedir = /
include =
 .
# Exclude the local borg directory in addition to the exclude patterns defined
# in the [DEFAULT] section.
exclude =
 ${DEFAULT:exclude}
 ./borg

# Repository definitions are how we tell syborg where to find and unlock the
# actual borg repositories. The method to do this is by setting one or more
# environment variables. Clearly, at least BORG_REPO must be set. 
[repository.local]
# My local repository
env.BORG_REPO = /borg/local

[repository.sg4tb]
# When I plug my seagate 4tb drive, it will automatically be mounted to
# /borg/sg4tb and the "all-sg4tb" job will start.
env.BORG_REPO = /borg/sg4tb/borg

[repository.cloud]
# This illustrates how syborg integrates with rclone. /borg/cloud is a local
# repository, but since we defined the "rclone.mirrors" option below, syborg
# will use rclone to sync the repository to one or more remotes that were
# previously defined with rclone config.
# 
# It is recommended to lock the rclone config with a passphrase, which syborg
# unlocks if a passcommand is specified (see [DEFAULT] section below)
env.BORG_REPO = /borg/cloud
rclone.mirrors = dropbox:borg,onedrive:borg,gdrive:borg
# Borg documentation doesn't recommend manually copying repositories between
# hosts, because problems on the source will be propagated to the remote copy.
# In our case, if the hard drive fails and starts to return corrupted data, we
# would propagate the corruption to all 3 mirrored targets.

# While it is not a perfect solution, syborg provides the 'rclone.check' option
# which can be used to prevent such scenarios. By setting rclone.check to
# "yes", syborg will run "borg check --verbose --progress --verify-data"
# before invoking rclone. If the integrity check fails, rclone will not run and
# the remote repository not be touched.

# The default value for "rclone.check" is "no", because syborg assumes you will
# already have multiple repositories with copies of the data that can be used to
# recover the repository later. Note that this option is unnecessary when using
# a checksumming filesystem such as btrfs or zfs.
rclone.check = yes

[repository.rsyncnet]
# Example of how to define a remote repository over ssh. The BORG_REPO value
# below assumes there's an rsyncnet host defined in ~/.ssh/config for the user
# that will run syborg. Here's an example config:
#
#   Host rsyncnet
#     HostName hostname.rsync.net
#     User 00000
#     IdentityFile ~/.ssh/id_rsyncnet
#
# It is recommended to lock the ssh key with a passphrase, which syborg will
# unlock if a passcommand is specified (see [DEFAULT] section below)
env.BORG_REPO = rsyncnet:borg
# rsync.net uses a non-standard path for borg 1.x, so we must specify it with
# BORG_REMOTE_PATH
env.BORG_REMOTE_PATH = borg1

# The [DEFAULT] section is special in that it provides fallback values for all
# other sections in the file. See python configparser documentation for details:
# https://docs.python.org/3/library/configparser.html
[DEFAULT]
# BORG_PASSCOMMAND is a command that can be used to obtain the repository
# passphrase. A popular choice is to store the passphrase in gnome keyring and
# retrieve it with "secret-tool". If the backup is running as root, but the
# gnome keyring is for user "tarruda", you also need to set DISPLAY and use
# "sudo" to run secret-tool as the keyring owner. For example:
env.DISPLAY = :0
env.BORG_PASSCOMMAND = sudo -u tarruda secret-tool lookup borg-backup main-passphrase
# Another possible option is to use systemd-ask-password, which will work if the
# gtk password agent is properly installed.
env.BORG_PASSCOMMAND = systemd-ask-password --no-tty Enter syborg unlock passphrase
# No matter which option is used, syborg will use keyctl to cache passphrases
# for 24h in the keyring of the user running the command
# Here we reuse the same password for locking rclone config...
env.RCLONE_PASSWORD_COMMAND = ${env.BORG_PASSCOMMAND}
# ...and ssh key.
env.SYBORG_SSH_PASSCOMMAND = ${env.BORG_PASSCOMMAND}
# The ssh key can be specified here, if not set in the ssh config
env.SYBORG_SSH_KEY = ~/.ssh/id_rsyncnet
# list of exclude patterns that will be passed to borg create
exclude =
  *~
  *.swp
  *.swo
  *.zwc
  *.class
  *.o
  *.pyc
  *.pyo
  *.pyd
  *.elc
  .netrwhist
  cscope.out
  __pycache__
  */.cache/*
