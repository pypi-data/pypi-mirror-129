Metadata-Version: 2.1
Name: mosaicml
Version: 0.3.0
Summary: composing methods for ML training efficiency
Home-page: https://github.com/mosaicml/composer
Author: MosaicML
Author-email: team@mosaicml.com
License: UNKNOWN
Platform: UNKNOWN
Classifier: Programming Language :: Python :: 3
Requires-Python: >=3.7
Description-Content-Type: text/markdown
License-File: LICENSE
License-File: LICENSE_HEADER
Requires-Dist: pyyaml (>=5.4.1)
Requires-Dist: tqdm (>=4.62.3)
Requires-Dist: torchmetrics (>=0.5.1)
Requires-Dist: torch-optimizer (==0.1.0)
Requires-Dist: torchvision (>=0.9.0)
Requires-Dist: torch (>=1.9)
Requires-Dist: argparse (>=1.4.0)
Requires-Dist: yahp (>=0.0.13)
Provides-Extra: all
Requires-Dist: sphinx-argparse (>=0.3.1) ; extra == 'all'
Requires-Dist: pytest-timeout (>=1.4.2) ; extra == 'all'
Requires-Dist: coverage[toml] (>=6.1.1) ; extra == 'all'
Requires-Dist: junitparser (>=2.1.1) ; extra == 'all'
Requires-Dist: pytest (>=6.2.0) ; extra == 'all'
Requires-Dist: sphinx-rtd-theme (>=1.0.0) ; extra == 'all'
Requires-Dist: wandb (>=0.12.2) ; extra == 'all'
Requires-Dist: sphinx-markdown-tables (>=0.0.15) ; extra == 'all'
Requires-Dist: sphinx-copybutton (>=0.4.0) ; extra == 'all'
Requires-Dist: ipython (>=7.29.0) ; extra == 'all'
Requires-Dist: myst-parser (>=0.15.2) ; extra == 'all'
Requires-Dist: recommonmark (>=0.7.1) ; extra == 'all'
Requires-Dist: sphinx (>=4.2.0) ; extra == 'all'
Requires-Dist: testbook (>=0.4.2) ; extra == 'all'
Requires-Dist: yamllint (>=1.26.2) ; extra == 'all'
Requires-Dist: scikit-learn (>=1.0.1) ; extra == 'all'
Requires-Dist: ipykernel (>=6.5.0) ; extra == 'all'
Requires-Dist: jupyter (>=1.0.0) ; extra == 'all'
Requires-Dist: yapf (>=0.13.0) ; extra == 'all'
Requires-Dist: datasets (>=1.14.0) ; extra == 'all'
Requires-Dist: transformers (>=4.11.3) ; extra == 'all'
Requires-Dist: monai (>=0.7.0) ; extra == 'all'
Requires-Dist: sphinxext.opengraph (>=0.4.2) ; extra == 'all'
Requires-Dist: sphinxcontrib.katex (>=0.8.6) ; extra == 'all'
Requires-Dist: isort (>=5.9.3) ; extra == 'all'
Provides-Extra: base
Provides-Extra: dev
Requires-Dist: junitparser (>=2.1.1) ; extra == 'dev'
Requires-Dist: coverage[toml] (>=6.1.1) ; extra == 'dev'
Requires-Dist: pytest (>=6.2.0) ; extra == 'dev'
Requires-Dist: yapf (>=0.13.0) ; extra == 'dev'
Requires-Dist: isort (>=5.9.3) ; extra == 'dev'
Requires-Dist: ipython (>=7.29.0) ; extra == 'dev'
Requires-Dist: ipykernel (>=6.5.0) ; extra == 'dev'
Requires-Dist: jupyter (>=1.0.0) ; extra == 'dev'
Requires-Dist: yamllint (>=1.26.2) ; extra == 'dev'
Requires-Dist: pytest-timeout (>=1.4.2) ; extra == 'dev'
Requires-Dist: recommonmark (>=0.7.1) ; extra == 'dev'
Requires-Dist: sphinx (>=4.2.0) ; extra == 'dev'
Requires-Dist: sphinx-copybutton (>=0.4.0) ; extra == 'dev'
Requires-Dist: sphinx-markdown-tables (>=0.0.15) ; extra == 'dev'
Requires-Dist: sphinx-argparse (>=0.3.1) ; extra == 'dev'
Requires-Dist: sphinxcontrib.katex (>=0.8.6) ; extra == 'dev'
Requires-Dist: sphinxext.opengraph (>=0.4.2) ; extra == 'dev'
Requires-Dist: sphinx-rtd-theme (>=1.0.0) ; extra == 'dev'
Requires-Dist: testbook (>=0.4.2) ; extra == 'dev'
Requires-Dist: myst-parser (>=0.15.2) ; extra == 'dev'
Provides-Extra: nlp
Requires-Dist: transformers (>=4.11.3) ; extra == 'nlp'
Requires-Dist: datasets (>=1.14.0) ; extra == 'nlp'
Provides-Extra: unet
Requires-Dist: monai (>=0.7.0) ; extra == 'unet'
Requires-Dist: scikit-learn (>=1.0.1) ; extra == 'unet'
Provides-Extra: wandb
Requires-Dist: wandb (>=0.12.2) ; extra == 'wandb'

# MosaicML Composer

MosaicML `Composer` contains a library of methods, and ways to compose them together for more efficient ML training. We aim to ease the transition from research to industry through reproducible code and rigorous benchmarking.

The library features:
* Implementation of 20+ efficiency methods curated from the research community
* Standardized approach to implement and compose efficiency methods, extended from two-way callbacks ([Howard et al, 2020](https://arxiv.org/abs/2002.04688))
* Easy way to access our methods either directly for your trainer loops, or through the MosaicML Trainer.

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mosaicml/composer/blob/main/examples/composer.ipynb)


## Installing Composer

To install `Composer`:
```
pip install mosaicml
```

## Using Composer

A few ways to use `Composer`:

1. Import the functional form of our methods:

```python
from composer import functional as CF
import torchvision

model = torchvision.models.resnet50()

# replaces eligible layers with BlurPool (Zhang, 2019)
CF.apply_blurpool(model)

for epoch in range(max_epochs):
    for data in your_data:
        ...
    # freeze layers at the end of every epoch
    CF.freeze_layers(model)

```

We have a growing collection of deeply characterized methods, see [Methods](https://www.mosaicml.com/methods).

2. Compose methods together using our `Trainer`:

```python
from composer import trainer, algorithms, Trainer

trainer_hparams = trainer.load("resnet50")
trainer_hparams.algorithms = algorithms.load_multiple("squeeze_excite", "scale_schedule")
trainer_hparams.set_datadir('your/dataset/path/')

learner = Trainer.create_from_hparams(hparams=trainer_hparams)
learner.fit()

```

## Composer TL;DR

Composer methods are either curated from the literature, or developed internally, and rigorously measured on public benchmarks. To explore the benchmarks, see our [MosaicML Explorer](https://app.mosaicml.com).

To compose methods together, we used the excellent two-way callbacks system ([Howard et al, 2020](https://arxiv.org/abs/2002.04688)). Each method is implemented as a two-way callback, and also in functional form for standalone access and extension.

## Documentation

See [our documentation](https://mosaicml-composer.readthedocs-hosted.com/en/stable/) for installation instructions and how to get started.

## Community

We welcome contributions of new methods, models, and datasets Also join our [community slack](https://join.slack.com/t/mosaicmlworkspace/shared_invite/zt-w0tiddn9-WGTlRpfjcO9J5jyrMub1dg) to talk about ML training efficiency!


Our library builds upon ideas from the broader ML community! We are exploring integrations into other libraries to make the Composer efficiency methods available to all.


